{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import openai\n",
    "from deepeval.metrics import GEval\n",
    "from deepeval.test_case import LLMTestCase, LLMTestCaseParams\n",
    "\n",
    "# Load environment variables from .env file in the same directory\n",
    "env_path = Path().absolute() / '.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# Configure OpenAI\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "MODEL_NAME = os.getenv('OPENAI_MODEL', 'gpt-4')\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in environment variables\")\n",
    "\n",
    "# Set OpenAI API key globally\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "print(\"OpenAI API key loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correctness evaluation metric\n",
    "correctness_metric = GEval(\n",
    "    name=\"Correctness\",\n",
    "    criteria=\"Determine whether the actual output is factually correct based on the expected output.\",\n",
    "    evaluation_steps=[\n",
    "        \"Check whether the facts in 'actual output' contradicts any facts in 'expected output'\",\n",
    "        \"You should also heavily penalize omission of detail\",\n",
    "        \"Vague language, or contradicting OPINIONS, are OK\"\n",
    "    ],\n",
    "    evaluation_params=[\n",
    "        LLMTestCaseParams.INPUT,\n",
    "        LLMTestCaseParams.ACTUAL_OUTPUT,\n",
    "        LLMTestCaseParams.EXPECTED_OUTPUT\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\ProgramData\\anaconda3\\envs\\ragbench-env\\lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\ProgramData\\anaconda3\\envs\\ragbench-env\\lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\ProgramData\\anaconda3\\envs\\ragbench-env\\lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\ProgramData\\anaconda3\\envs\\ragbench-env\\lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\ProgramData\\anaconda3\\envs\\ragbench-env\\lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\ProgramData\\anaconda3\\envs\\ragbench-env\\lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctness Score: 0.24546227667201054\n",
      "Reason: The actual output allows for interpretation and does not provide the specific fact that the cat ran up the tree as mentioned in the expected output.\n"
     ]
    }
   ],
   "source": [
    "# Create test case\n",
    "test_case = LLMTestCase(\n",
    "    input=\"The dog chased the cat up the tree, who ran up the tree?\",\n",
    "    actual_output=\"It depends, some might consider the cat, while others might argue the dog.\",\n",
    "    expected_output=\"The cat.\"\n",
    ")\n",
    "\n",
    "# Run correctness evaluation\n",
    "correctness_metric.measure(test_case)\n",
    "print(f\"Correctness Score: {correctness_metric.score}\")\n",
    "print(f\"Reason: {correctness_metric.reason}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragbench-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
